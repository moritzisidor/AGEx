#!/usr/bin/env python3
"""
grade_answer_sheets_pdf.py
--------------------------------
Grades scanned single-choice answer sheets generated by the companion generator.

Key features
- Reads ALL scanned answer sheets from ONE multi-page PDF (one page per sheet)
- Detects 4 black corner markers, warps to canonical layout coordinates
- Infers Student ID from the scan itself (OCR on the "Student ID: ..." field)
  - Uses layout.json's student_id_print box when available
  - Uses robust fallbacks and multiple preprocessing variants
  - Falls back to filename digits only if OCR fails
- Supports "expected roster" via --student-id-start + --student-id-count:
  - If a student's sheet is missing, writes a row with NA values

Dependencies:
  pip install opencv-python numpy pytesseract

Usage:
  python3 grade_answer_sheets_pdf.py --layout Quiz_out/layout.json --pdf scans --out results.csv \
      --student-id-start 1 --student-id-count 10
"""
from __future__ import annotations

import argparse
import csv
import glob
import json
import os
import re
from typing import Dict, Any, List, Optional, Tuple

import cv2
import numpy as np
import pytesseract
from pdf2image import convert_from_path
import sys
import time


# ----------------------------
# Student-ID OCR fallback (no Tesseract required)
# ----------------------------
def _build_digit_templates(size: int = 28) -> Dict[int, List[np.ndarray]]:
    """Build a small bank of digit templates using OpenCV fonts."""
    fonts = [
        cv2.FONT_HERSHEY_SIMPLEX,
        cv2.FONT_HERSHEY_COMPLEX,
        cv2.FONT_HERSHEY_TRIPLEX,
        cv2.FONT_HERSHEY_DUPLEX,
    ]
    scales = [0.9, 1.0, 1.1, 1.2]
    thicknesses = [2, 3]
    bank: Dict[int, List[np.ndarray]] = {d: [] for d in range(10)}
    for d in range(10):
        for font in fonts:
            for sc in scales:
                for th in thicknesses:
                    canvas = np.zeros((size + 12, size + 12), dtype=np.uint8)
                    cv2.putText(canvas, str(d), (6, size + 2), font, sc, 255, th, cv2.LINE_AA)
                    ys, xs = np.where(canvas > 0)
                    if len(xs) == 0:
                        continue
                    x1, x2 = xs.min(), xs.max()
                    y1, y2 = ys.min(), ys.max()
                    crop = canvas[y1:y2 + 1, x1:x2 + 1]
                    crop = cv2.resize(crop, (size, size), interpolation=cv2.INTER_AREA)
                    bank[d].append(crop)
    return bank


_DIGIT_TEMPLATES = None  # lazy init


def _template_match_digit(digit_bin_inv: np.ndarray) -> Optional[int]:
    """Match a single digit image (binary-inverted: strokes=white) against templates."""
    global _DIGIT_TEMPLATES
    if _DIGIT_TEMPLATES is None:
        _DIGIT_TEMPLATES = _build_digit_templates(28)

    img = cv2.resize(digit_bin_inv, (28, 28), interpolation=cv2.INTER_AREA)

    best_d = None
    best_score = -1.0
    for d, tpl_list in _DIGIT_TEMPLATES.items():
        for tpl in tpl_list:
            score = float(cv2.matchTemplate(img, tpl, cv2.TM_CCOEFF_NORMED)[0, 0])
            if score > best_score:
                best_score = score
                best_d = d

    # require at least some confidence (prevents random noise)
    if best_score < 0.25:
        return None
    return best_d


def _group_and_read_digits(roi_gray: np.ndarray, expected_digits: int = 3) -> Optional[str]:
    """Extract a group of N digit-like blobs from roi and read them via template matching."""
    if roi_gray.size == 0:
        return None

    # upscale helps segmentation
    r = cv2.resize(roi_gray, None, fx=5.0, fy=5.0, interpolation=cv2.INTER_CUBIC)
    r = cv2.GaussianBlur(r, (3, 3), 0)
    _, bin_inv = cv2.threshold(r, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    cnts, _ = cv2.findContours(bin_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    if not cnts:
        return None

    H, W = bin_inv.shape[:2]

    # collect plausible components
    comps = []
    for c in cnts:
        x, y, w, h = cv2.boundingRect(c)
        if w * h < 250:
            continue
        if h < 0.20 * H or h > 0.85 * H:
            continue
        if w < 0.03 * W or w > 0.35 * W:
            continue
        ar = w / float(h)
        if not (0.20 <= ar <= 1.20):  # digit-ish
            continue
        comps.append((x, y, w, h))

    if len(comps) < expected_digits:
        return None

    # Choose a set of N components that align horizontally and are close together.
    comps = sorted(comps, key=lambda b: b[0])
    best = None
    best_score = -1.0

    for i in range(0, len(comps) - expected_digits + 1):
        group = comps[i:i + expected_digits]
        ys = [g[1] + g[3] / 2 for g in group]
        hs = [g[3] for g in group]
        # alignment score: low vertical spread and similar heights, plus compact x spread
        yspread = max(ys) - min(ys)
        hspread = max(hs) - min(hs)
        xspread = (group[-1][0] + group[-1][2]) - group[0][0]
        score = 1.0 / (1.0 + yspread) + 1.0 / (1.0 + hspread) + 1.0 / (1.0 + xspread / 10.0)
        if score > best_score:
            best_score = score
            best = group

    if best is None:
        return None

    out = ""
    for (x, y, w, h) in best:
        digit = bin_inv[y:y + h, x:x + w]
        d = _template_match_digit(digit)
        if d is None:
            return None
        out += str(d)

    if expected_digits and len(out) != expected_digits:
        return None
    return out


# ----------------------------
# Geometry helpers
# ----------------------------
def order_points(pts: np.ndarray) -> np.ndarray:
    """Order 4 points as (tl, tr, br, bl)."""
    rect = np.zeros((4, 2), dtype=np.float32)
    s = pts.sum(axis=1)
    rect[0] = pts[np.argmin(s)]
    rect[2] = pts[np.argmax(s)]
    diff = np.diff(pts, axis=1).reshape(-1)
    rect[1] = pts[np.argmin(diff)]
    rect[3] = pts[np.argmax(diff)]
    return rect


def find_corner_markers(binary_inv: np.ndarray, min_area: float) -> Optional[np.ndarray]:
    """
    Find 4 large square-ish dark blobs (corner markers).
    binary_inv is THRESH_BINARY_INV: white pixels correspond to dark regions in original.
    Returns (4,2) float32 centers or None.
    """
    cnts, _ = cv2.findContours(binary_inv, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    h, w = binary_inv.shape[:2]

    candidates: List[Tuple[float, float, np.ndarray]] = []
    for c in cnts:
        area = cv2.contourArea(c)
        if area < min_area:
            continue
        peri = cv2.arcLength(c, True)
        approx = cv2.approxPolyDP(c, 0.03 * peri, True)
        if len(approx) != 4:
            continue
        x, y, ww, hh = cv2.boundingRect(approx)
        if hh <= 0:
            continue
        ar = ww / float(hh)
        if not (0.70 <= ar <= 1.40):
            continue

        # square-ish and reasonably "solid"
        roi = binary_inv[y:y+hh, x:x+ww]
        if roi.size == 0:
            continue
        fill = float(cv2.countNonZero(roi)) / float(roi.shape[0] * roi.shape[1])
        if fill < 0.40:  # marker is a filled square; checkbox outlines won't pass
            continue

        cx = x + ww / 2.0
        cy = y + hh / 2.0

        # Prefer blobs near corners
        corner_score = min(
            np.hypot(cx - 0, cy - 0),
            np.hypot(cx - (w - 1), cy - 0),
            np.hypot(cx - 0, cy - (h - 1)),
            np.hypot(cx - (w - 1), cy - (h - 1)),
        )
        candidates.append((area, -corner_score, np.array([cx, cy], dtype=np.float32)))

    if len(candidates) < 4:
        return None

    candidates.sort(reverse=True, key=lambda t: (t[0], t[1]))
    centers = np.array([c[2] for c in candidates[:20]], dtype=np.float32)

    # Choose 4 points far from image center (greedy diversification)
    center_img = np.array([w / 2.0, h / 2.0], dtype=np.float32)
    d = np.linalg.norm(centers - center_img, axis=1)
    chosen = [int(np.argmax(d))]
    while len(chosen) < 4:
        best_i = None
        best_dist = -1.0
        for i in range(len(centers)):
            if i in chosen:
                continue
            dist_to_chosen = min(np.linalg.norm(centers[i] - centers[j]) for j in chosen)
            if dist_to_chosen > best_dist:
                best_dist = dist_to_chosen
                best_i = i
        if best_i is None:
            break
        chosen.append(best_i)

    if len(chosen) != 4:
        return None
    return centers[chosen]


def warp_to_canonical(gray: np.ndarray, markers: np.ndarray, layout: Dict[str, Any]) -> np.ndarray:
    """Warp scan into the canonical pixel canvas.

    We map detected marker centers to the expected marker centers stored in layout.json (if present),
    otherwise we fall back to mapping to the canvas corners (legacy).
    """
    Wc = int(layout["canonical_w_px"])
    Hc = int(layout["canonical_h_px"])

    src = order_points(markers)

    # Default legacy fallback: map marker centers to the canvas corners.
    # This is *wrong* if the markers are printed inside the page margins, but we keep it
    # as a last resort.
    dst = np.array([[0, 0], [Wc - 1, 0], [Wc - 1, Hc - 1], [0, Hc - 1]], dtype=np.float32)

    marker = layout.get("marker") or {}
    page_w = float(layout["page_width_pt"])
    page_h = float(layout["page_height_pt"])

    # Preferred: explicit marker centers (newer generator)
    centers = marker.get("centers_pt")
    pts: List[List[float]] = []
    if isinstance(centers, list) and len(centers) == 4:
        for c in centers:
            try:
                x_pt = float(c["x_pt"])
                y_pt = float(c["y_pt"])
            except Exception:
                pts = []
                break
            x_px = x_pt / page_w * Wc
            y_px = Hc - (y_pt / page_h * Hc)  # PDF bottom-left -> image top-left
            pts.append([x_px, y_px])

    # Fallback: older layout.json stored only margin+size; compute expected centers.
    # This is the common case for the original generator.
    if not pts and ("margin_pt" in marker) and ("size_pt" in marker):
        try:
            margin_pt = float(marker["margin_pt"])
            size_pt = float(marker["size_pt"])
            half = size_pt / 2.0
            computed = [
                # (margin, margin)
                {"x_pt": margin_pt + half, "y_pt": margin_pt + half},
                # (W - margin - size, margin)
                {"x_pt": page_w - margin_pt - half, "y_pt": margin_pt + half},
                # (margin, H - margin - size)
                {"x_pt": margin_pt + half, "y_pt": page_h - margin_pt - half},
                # (W - margin - size, H - margin - size)
                {"x_pt": page_w - margin_pt - half, "y_pt": page_h - margin_pt - half},
            ]
            for c in computed:
                x_px = float(c["x_pt"]) / page_w * Wc
                y_px = Hc - (float(c["y_pt"]) / page_h * Hc)
                pts.append([x_px, y_px])
        except Exception:
            pts = []

    if len(pts) == 4:
        dst = order_points(np.array(pts, dtype=np.float32))

    M = cv2.getPerspectiveTransform(src, dst)
    return cv2.warpPerspective(gray, M, (Wc, Hc), flags=cv2.INTER_LINEAR)


# ----------------------------
# Grading helpers
# ----------------------------
def box_fill_ratio(bin_inv: np.ndarray, x: int, y: int, w: int, h: int, inset_frac: float = 0.10) -> float:
    """Fraction of dark pixels (white in bin_inv) inside an inset ROI of the checkbox."""
    ix = int(w * inset_frac)
    iy = int(h * inset_frac)
    x1 = max(0, x + ix)
    y1 = max(0, y + iy)
    x2 = min(bin_inv.shape[1], x + w - ix)
    y2 = min(bin_inv.shape[0], y + h - iy)
    roi = bin_inv[y1:y2, x1:x2]
    if roi.size == 0:
        return 0.0
    return float(cv2.countNonZero(roi)) / float(roi.shape[0] * roi.shape[1])



def estimate_background_fill_ratio(wbin_inv: np.ndarray, layout: Dict[str, Any], sample_scale: float = 1.0) -> float:
    """Estimate a 'background' fill ratio from a known-white area near the top-left corner marker.

    We sample a square patch just to the right of the top-left marker (after perspective warp),
    which should be blank paper. This gives a stable baseline even when a question has multiple
    marked boxes (where per-question median can become too high).

    Returns a ratio in [0,1] where higher means 'darker' (white pixels in wbin_inv).
    Falls back to a percentile-of-checkboxes estimate if marker metadata is missing.
    """
    Hc, Wc = wbin_inv.shape[:2]

    marker = layout.get("marker") or {}
    page_w = float(layout.get("page_width_pt") or 1.0)
    page_h = float(layout.get("page_height_pt") or 1.0)

    # Try to recover expected marker centers in canonical pixels (same approach as warp_to_canonical)
    pts: List[List[float]] = []
    centers = marker.get("centers_pt")
    if isinstance(centers, list) and len(centers) == 4:
        for c in centers:
            try:
                x_pt = float(c["x_pt"])
                y_pt = float(c["y_pt"])
            except Exception:
                pts = []
                break
            x_px = x_pt / page_w * Wc
            y_px = Hc - (y_pt / page_h * Hc)
            pts.append([x_px, y_px])

    if not pts and ("margin_pt" in marker) and ("size_pt" in marker):
        try:
            margin_pt = float(marker["margin_pt"])
            size_pt = float(marker["size_pt"])
            half = size_pt / 2.0
            computed = [
                {"x_pt": margin_pt + half, "y_pt": margin_pt + half},
                {"x_pt": page_w - margin_pt - half, "y_pt": margin_pt + half},
                {"x_pt": margin_pt + half, "y_pt": page_h - margin_pt - half},
                {"x_pt": page_w - margin_pt - half, "y_pt": page_h - margin_pt - half},
            ]
            for c in computed:
                x_px = float(c["x_pt"]) / page_w * Wc
                y_px = Hc - (float(c["y_pt"]) / page_h * Hc)
                pts.append([x_px, y_px])
        except Exception:
            pts = []

    # Derive a reasonable sampling square size from marker size if possible
    size_px: Optional[int] = None
    try:
        if "size_pt" in marker:
            size_pt = float(marker["size_pt"])
            size_px = int(round(((size_pt / page_w) * Wc + (size_pt / page_h) * Hc) / 2.0))
    except Exception:
        size_px = None

    if len(pts) == 4 and size_px and size_px > 4:
        pts_arr = order_points(np.array(pts, dtype=np.float32))
        tl = pts_arr[0]  # top-left marker center
        s = int(round(size_px * sample_scale))
        pad = max(2, int(round(0.15 * s)))

        # Sample a patch to the right of the marker, aligned vertically
        x1 = int(round(tl[0] + size_px / 2 + pad))
        y1 = int(round(tl[1] - s / 2))
        x2 = x1 + s
        y2 = y1 + s

        # Clamp
        x1 = max(0, min(Wc - 1, x1))
        y1 = max(0, min(Hc - 1, y1))
        x2 = max(0, min(Wc, x2))
        y2 = max(0, min(Hc, y2))

        roi = wbin_inv[y1:y2, x1:x2]
        if roi.size > 0:
            return float(cv2.countNonZero(roi)) / float(roi.shape[0] * roi.shape[1])

    # Fallback: use low percentile of all checkbox interiors as baseline
    try:
        all_r: List[float] = []
        for b in layout.get("boxes", []):
            x = int(round(float(b["x_pt"]) / float(layout["page_width_pt"]) * Wc))
            w = int(round(float(b["w_pt"]) / float(layout["page_width_pt"]) * Wc))
            h = int(round(float(b["h_pt"]) / float(layout["page_height_pt"]) * Hc))
            y_top = Hc - int(round((float(b["y_pt"]) + float(b["h_pt"])) / float(layout["page_height_pt"]) * Hc))
            y = y_top
            all_r.append(box_fill_ratio(wbin_inv, x, y, w, h))
        if all_r:
            return float(np.percentile(all_r, 20))
    except Exception:
        pass

    return 0.0


def load_layout(path: str) -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        layout = json.load(f)
    required = ["page_width_pt", "page_height_pt", "canonical_w_px", "canonical_h_px", "boxes", "answer_key"]
    for k in required:
        if k not in layout:
            raise ValueError(f"layout.json missing required key: {k}")
    # Per-question option counts: accept either the canonical key from the generator
    # ("per_question_option_counts") or the alias ("options_list") for convenience.
    if "per_question_option_counts" not in layout and "options_list" in layout:
        layout["per_question_option_counts"] = layout["options_list"]
    if "per_question_option_counts" not in layout:
        raise ValueError("layout.json missing required key: per_question_option_counts (or alias: options_list)")
    return layout


# ----------------------------
# OCR Student ID
# ----------------------------
def _preprocess_variants(gray: np.ndarray) -> List[np.ndarray]:
    """Generate a handful of OCR-friendly variants."""
    variants: List[np.ndarray] = []
    if gray.size == 0:
        return variants

    # upscale
    scale = 4
    big = cv2.resize(gray, (gray.shape[1]*scale, gray.shape[0]*scale), interpolation=cv2.INTER_CUBIC)
    variants.append(big)

    # blur + otsu
    blur = cv2.GaussianBlur(big, (3, 3), 0)
    _, th = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    variants.append(th)
    variants.append(255 - th)

    # adaptive threshold
    adap = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                cv2.THRESH_BINARY, 31, 7)
    variants.append(adap)
    variants.append(255 - adap)

    # a slightly sharpened version
    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]], dtype=np.float32)
    sharp = cv2.filter2D(big, -1, kernel)
    variants.append(sharp)

    return variants


def _best_digit_run(text: str) -> str:
    text = text.strip()
    # Prefer 3+ digits, otherwise any digits
    runs = re.findall(r"\d{3,}", text)
    if not runs:
        runs = re.findall(r"\d+", text)
    return max(runs, key=len) if runs else ""


def _ocr_from_roi(roi: np.ndarray, expected_digits: int = 3) -> Optional[str]:
    """Read digit runs from one ROI.

    Primary: Tesseract via pytesseract (if available).
    Fallback: pure-OpenCV template matching (works even if Tesseract isn't installed).
    """
    best = ""

    # 1) Try Tesseract (fastest when installed/configured)
    for v in _preprocess_variants(roi):
        for psm in ("7", "6", "8"):
            cfg = f"--psm {psm} -c tessedit_char_whitelist=0123456789"
            try:
                txt = pytesseract.image_to_string(v, config=cfg) or ""
            except Exception:
                # Common case on fresh systems: Tesseract binary not installed
                txt = ""
            run = _best_digit_run(txt)
            if len(run) > len(best):
                best = run

    if expected_digits and len(best) == expected_digits:
        return best
    if best:
        return best

    # 2) Fallback: template matching (no external binaries)
    return _group_and_read_digits(roi, expected_digits=expected_digits)



def _crop_by_layout(warped_gray: np.ndarray, layout: Dict[str, Any], pad_frac: float = 0.25) -> Optional[np.ndarray]:
    sid = layout.get("student_id_print") or {}
    if not all(k in sid for k in ("x_pt", "y_pt", "w_pt", "h_pt")):
        return None

    Wc = int(layout["canonical_w_px"])
    Hc = int(layout["canonical_h_px"])
    page_w = float(layout["page_width_pt"])
    page_h = float(layout["page_height_pt"])

    x = float(sid["x_pt"]) / page_w * Wc
    w = float(sid["w_pt"]) / page_w * Wc
    h = float(sid["h_pt"]) / page_h * Hc
    y_top = Hc - ((float(sid["y_pt"]) + float(sid["h_pt"])) / page_h * Hc)
    y = float(y_top)

    # pad (helps if warp is slightly off)
    px = w * pad_frac
    py = h * pad_frac
    x1 = int(max(0, x - px))
    y1 = int(max(0, y - py))
    x2 = int(min(Wc, x + w + px))
    y2 = int(min(Hc, y + h + py))

    roi = warped_gray[y1:y2, x1:x2]
    return roi if roi.size else None


def _crop_fallback(warped_gray: np.ndarray) -> Optional[np.ndarray]:
    """Fallback crop: upper-left region where 'Student ID: ...' is printed."""
    Hc, Wc = warped_gray.shape[:2]
    x1, y1 = 0, int(0.06 * Hc)
    x2, y2 = int(0.55 * Wc), int(0.35 * Hc)
    roi = warped_gray[y1:y2, x1:x2]
    return roi if roi.size else None


def ocr_student_id(warped_gray: np.ndarray, layout: Dict[str, Any], expected_digits: int = 3) -> Optional[str]:
    """OCR student ID from the warped scan."""
    candidates: List[str] = []

    roi1 = _crop_by_layout(warped_gray, layout, pad_frac=0.35)
    if roi1 is not None:
        r = _ocr_from_roi(roi1, expected_digits)
        if r:
            candidates.append(r)

    roi2 = _crop_fallback(warped_gray)
    if roi2 is not None:
        r = _ocr_from_roi(roi2, expected_digits)
        if r:
            candidates.append(r)

    if not candidates:
        return None

    # Choose candidate that best matches expected digit length; otherwise longest.
    def score(s: str) -> Tuple[int, int]:
        # higher is better
        length = len(s)
        length_match = 1 if (expected_digits and length == expected_digits) else 0
        return (length_match, length)

    best = max(candidates, key=score)
    return best


def ocr_student_id_from_raw(gray: np.ndarray, expected_digits: int = 3) -> Optional[str]:
    """Last-resort OCR directly on the unwarped scan.

    This helps if the perspective warp failed (e.g., because marker->dst mapping was wrong).
    We crop a generous top-left band where the Student ID is typically printed.
    """
    H, W = gray.shape[:2]
    x1, y1 = 0, int(0.04 * H)
    x2, y2 = int(0.65 * W), int(0.30 * H)
    roi = gray[y1:y2, x1:x2]
    if roi.size == 0:
        return None
    r = _ocr_from_roi(roi, expected_digits)
    if not r:
        return None
    # Prefer exact-length runs if possible
    if expected_digits and r.isdigit():
        return r
    return r


def infer_student_id_from_filename(image_path: str) -> str:
    stem = os.path.splitext(os.path.basename(image_path))[0]
    digits = "".join([c for c in stem if c.isdigit()])
    return digits if digits else stem


# ----------------------------
# Grade one image
# ----------------------------
def grade_cv2_image(img_bgr: np.ndarray, layout: Dict[str, Any], fill_threshold: float, ambiguity_margin: float) -> Dict[str, Any]:
    """Grade a single answer sheet from an already-loaded BGR image (OpenCV)."""
    img = img_bgr
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    blur = cv2.GaussianBlur(gray, (5, 5), 0)
    _, bin_inv = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    min_area = 0.0008 * bin_inv.shape[0] * bin_inv.shape[1]
    markers = find_corner_markers(bin_inv, min_area=float(min_area))
    if markers is None:
        return {"error": "markers_not_found"}

    warped = warp_to_canonical(gray, markers, layout)

    sid_digits = int(layout.get("student_id_digits") or 3)
    sid_ocr = ocr_student_id(warped, layout, expected_digits=sid_digits)
    if not sid_ocr:
        # last-resort OCR directly on the raw scan (helps if warp isn't perfect)
        sid_ocr = ocr_student_id_from_raw(gray, expected_digits=sid_digits)

    wblur = cv2.GaussianBlur(warped, (5, 5), 0)
    _, wbin_inv = cv2.threshold(wblur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Build per-question box list
    boxes_by_q: Dict[int, List[Dict[str, Any]]] = {}
    for b in layout["boxes"]:
        q = int(b["q"])
        boxes_by_q.setdefault(q, []).append(b)
    for q in boxes_by_q:
        boxes_by_q[q].sort(key=lambda bb: int(bb["opt"]))

    per_q_counts: List[int] = [int(x) for x in layout["per_question_option_counts"]]
    answer_key: List[int] = [int(x) for x in layout["answer_key"]]
    num_questions = int(layout.get("num_questions") or len(per_q_counts))

    Wc = int(layout["canonical_w_px"])
    Hc = int(layout["canonical_h_px"])

    bg_ratio = estimate_background_fill_ratio(wbin_inv, layout)

    picked: List[Optional[int]] = []
    blanks = 0
    invalid = 0
    correct = 0

    for qi in range(1, num_questions + 1):
        k = per_q_counts[qi - 1]
        bxs = boxes_by_q.get(qi, [])
        if len(bxs) < k:
            picked.append(None)
            invalid += 1
            continue

        ratios: List[float] = []
        for oi in range(k):
            bb = bxs[oi]
            x = int(round(float(bb["x_pt"]) / float(layout["page_width_pt"]) * Wc))
            w = int(round(float(bb["w_pt"]) / float(layout["page_width_pt"]) * Wc))
            h = int(round(float(bb["h_pt"]) / float(layout["page_height_pt"]) * Hc))
            y_top = Hc - int(round((float(bb["y_pt"]) + float(bb["h_pt"])) / float(layout["page_height_pt"]) * Hc))
            y = y_top
            ratios.append(box_fill_ratio(wbin_inv, x, y, w, h))

        best = int(np.argmax(ratios))
        best_val = float(ratios[best])
        sorted_vals = sorted(ratios, reverse=True)
        second_val = float(sorted_vals[1]) if len(sorted_vals) > 1 else 0.0

        eff_thresh = max(float(fill_threshold), float(bg_ratio) + 0.05)

        # If 2+ boxes clear the absolute fill threshold, treat as multi-mark (invalid)
        filled_ct = sum(1 for r in ratios if r >= float(fill_threshold))
        if filled_ct >= 2:
            picked.append(None)
            invalid += 1
            continue

        if best_val < eff_thresh:
            picked.append(None)
            blanks += 1
            continue

        if (best_val - second_val) < ambiguity_margin:
            picked.append(None)
            invalid += 1
            continue

        picked.append(best)
        if best == answer_key[qi - 1]:
            correct += 1

    return {
        "student_id_ocr": sid_ocr,
        "correct": int(correct),
        "total questions": int(num_questions),
        "score %": float(100.0 * correct / max(1, num_questions)),
        "blanks": int(blanks),
        "invalid": int(invalid),
        "wrong": int(num_questions - correct - blanks - invalid),
        "picked": picked,
    }


# ----------------------------
# Main
# ----------------------------

def grade_image(image_path: str, layout: Dict[str, Any], fill_threshold: float, ambiguity_margin: float) -> Dict[str, Any]:
    """Backward-compatible wrapper: accepts ONLY PDFs (grades first page)."""
    ext = os.path.splitext(image_path)[1].lower()
    if ext != ".pdf":
        raise ValueError(f"Only PDF input is supported now (got {ext}). Provide a multi-page PDF via --pdf.")
    pil_img = convert_from_path(image_path, dpi=300)[0]
    img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
    return grade_cv2_image(img, layout, fill_threshold, ambiguity_margin)

def load_pdf_pages(pdf_path: str, dpi: int = 300) -> List[Tuple[int, np.ndarray]]:
    """Load a multi-page PDF and return list of (page_number_1based, cv2 BGR image)."""
    if not pdf_path.lower().endswith(".pdf"):
        raise ValueError(f"Expected a PDF file, got: {pdf_path}")
    if not os.path.exists(pdf_path):
        raise FileNotFoundError(pdf_path)

    pil_pages = convert_from_path(pdf_path, dpi=dpi)
    pages: List[Tuple[int, np.ndarray]] = []
    for i, pil_img in enumerate(pil_pages, start=1):
        img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        pages.append((i, img))
    return pages


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--layout", required=True, help="Path to layout.json generated by the generator")
    ap.add_argument("--scans", required=True, help="Path to ONE multi-page PDF containing all scanned answer sheets")
    ap.add_argument("--out", default="results.csv", help="Output CSV path")
    ap.add_argument("--fill-threshold", type=float, default=0.18,
                    help="Min fill ratio to accept a marked box range: (0,1) \n default: 0.18")
    ap.add_argument("--ambiguity-margin", type=float, default=0.06,
                    help="Min difference between top-2 ratios to accept as unambiguous range: (0,1). \n default: 0.06")
    ap.add_argument("--student-id-start", type=int, default=None,
                    help="First expected student ID (inclusive). If provided with --student-id-count, missing sheets are written as NA.")
    ap.add_argument("--student-id-count", type=int, default=None,
                    help="Number of expected student IDs. If provided with --student-id-start, missing sheets are written as NA.")
    args = ap.parse_args()

    layout = load_layout(args.layout)
    sid_digits = int(layout.get("student_id_digits") or 3)

    pages = load_pdf_pages(args.scans, dpi=300)
    if not pages:
        raise SystemExit(f"No pages found in PDF: {args.scans}")

    graded: Dict[str, Dict[str, Any]] = {}
    duplicates: List[Tuple[str, str]] = []
    ocr_fail_files: List[str] = []
    unassigned_files: List[str] = []

    pdf_base = os.path.basename(args.scans)
    total_pages = len(pages)
    processed_pages = 0
    start_ts = time.time()
    for page_no, img in pages:
        processed_pages += 1
        # Progress update before processing this page
        try:
            elapsed = time.time() - start_ts
            avg = elapsed / processed_pages if processed_pages else 0.0
            sys.stdout.write(f"\rGrading sheets: {processed_pages}/{total_pages} (page {page_no})")
            sys.stdout.flush()
        except Exception:
            pass

        source_id = f"{pdf_base}#p{page_no}"
        result = grade_cv2_image(img, layout, args.fill_threshold, args.ambiguity_margin)

        sid = (result.get("student_id_ocr") or "").strip()
        if sid.isdigit():
            sid = sid.zfill(sid_digits)

        if not sid:
            # last resort fallback (still allows grading, but marks OCR failure)
            sid = infer_student_id_from_filename(source_id)
            if sid.isdigit():
                sid = sid.zfill(sid_digits)
            ocr_fail_files.append(source_id)
            result["error"] = (result.get("error") or "ocr_failed")

        # If we still don't have a numeric ID (e.g., filename has no digits), don't invent one.
        # Keep the scan out of the roster-keyed results, but report it.
        if (not sid.isdigit()) and (args.student_id_start is not None and args.student_id_count is not None):
            unassigned_files.append(source_id)
            continue

        if sid in graded:
            duplicates.append((sid, source_id))
            # keep the one with higher score (useful if one scan is blurred)
            prev = graded[sid]
            prev_score = float(prev.get("score %") or 0.0) if isinstance(prev.get("score %"), (float, int)) else 0.0
            new_score = float(result.get("score %") or 0.0) if isinstance(result.get("score %"), (float, int)) else 0.0
            if new_score > prev_score:
                graded[sid] = {"student_id": sid, **result}
            continue

        graded[sid] = {"student_id": sid, **result}

    # Expected IDs roster
    try:
        sys.stdout.write("\n")
    except Exception:
        pass
    if args.student_id_start is not None and args.student_id_count is not None:
        expected_ids = [str(i).zfill(sid_digits) for i in range(args.student_id_start, args.student_id_start + args.student_id_count)]
    else:
        def _sort_key(s: str):
            try:
                return (0, int(s))
            except Exception:
                return (1, s)
        expected_ids = sorted(graded.keys(), key=_sort_key)

    total_questions = int(layout.get("num_questions") or len(layout.get("per_question_option_counts", []))) or 0

    rows: List[Dict[str, Any]] = []
    for sid in expected_ids:
        if sid in graded:
            rows.append(graded[sid])
        else:
            rows.append({
                "student_id": sid,
                "total questions": total_questions if total_questions else "NA",
                "correct": "NA",
                "wrong": "NA",
                "blanks": "NA",
                "invalid": "NA",
                "score %": "NA",
                "error": "missing_sheet",
            })

    with open(args.out, "w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        w.writerow(["student_id", "total questions", "correct", "wrong", "blanks", "invalid", "score %", "error"])
        for r in rows:
            sp = r.get("score %", "")
            w.writerow([
                r.get("student_id", ""),
                r.get("total questions", ""),
                r.get("correct", ""),
                r.get("wrong", ""),
                r.get("blanks", ""),
                r.get("invalid", ""),
                f"{sp:.2f}" if isinstance(sp, (float, int)) else (sp if isinstance(sp, str) else ""),
                r.get("error", ""),
            ])

    print(f"Wrote {args.out} ({len(rows)} rows).")
    if ocr_fail_files:
        print(f"Warning: OCR failed for {len(ocr_fail_files)} file(s): {', '.join(ocr_fail_files[:8])}" + (" ..." if len(ocr_fail_files) > 8 else ""))
    if unassigned_files:
        print(
            f"Warning: {len(unassigned_files)} scan(s) could not be assigned to a numeric Student ID (no OCR + no digits in filename): "
            f"{', '.join(unassigned_files[:8])}" + (" ..." if len(unassigned_files) > 8 else "")
        )
    if duplicates:
        print(f"Note: Duplicate student IDs encountered for {len(duplicates)} scan(s). Kept the best-scoring scan per ID.")

if __name__ == "__main__":
    main()